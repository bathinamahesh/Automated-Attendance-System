{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6fafca84",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import os\n",
    "import cv2\n",
    "import pandas as pd\n",
    "import datetime\n",
    "\n",
    "img_size = 64\n",
    "\n",
    "loaded_model = tf.keras.models.load_model('person_classifier_500.h5')\n",
    "\n",
    "results = pd.DataFrame(columns=['Image', 'Person', 'Date'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "737a7323",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Anand', 'Angel', 'BhargaviS', 'Devi', 'Dsrilakshmi', 'Falak', 'guravaya', 'Harshitha', 'Idris', 'jareen', 'Jessika', 'Jyothi', 'Khasim', 'lakshmiPrasanna', 'Mani', 'Moulichand', 'Mounika', 'Nagraju', 'neeraja', 'Pawan', 'Priyanka', 'sai', 'Sangeetha', 'Santhvana', 'Satya', 'Sirisha', 'Sowjanya', 'Sravani', 'Srilakshmi', 'sripavan', 'Swathi', 'Thanuja', 'Thrisali', 'VaraLakshmi', 'Vineela', 'Vineeth']\n"
     ]
    }
   ],
   "source": [
    "# specify the path of the directory\n",
    "directory_path = \"C:/Users/Naveen/Documents/Mproject/new/dataset/train/\"\n",
    "\n",
    "# create an empty list to store the directory names\n",
    "names = []\n",
    "\n",
    "# use the os.listdir() function to get a list of all directory names in the specified path\n",
    "for filename in os.listdir(directory_path):\n",
    "    # check if the filename is a directory\n",
    "    if os.path.isdir(os.path.join(directory_path, filename)):\n",
    "        # if it is a directory, append the name to the list\n",
    "        names.append(filename)\n",
    "\n",
    "# print the list of directory names\n",
    "print(names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "171c3221",
   "metadata": {},
   "outputs": [],
   "source": [
    "import dlib\n",
    "\n",
    "# Load the detector\n",
    "detector = dlib.get_frontal_face_detector()\n",
    "\n",
    "# Load the predictor\n",
    "predictor = dlib.shape_predictor(\"shape_predictor_68_face_landmarks.dat\")\n",
    "\n",
    "# Load the image\n",
    "img = cv2.imread(\"image.jpg\")\n",
    "\n",
    "# Convert image to grayscale\n",
    "gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "# Detect faces using HOG + Linear SVM detector\n",
    "faces = detector(gray, 1)\n",
    "\n",
    "# Create the \"faces\" directory if it doesn't exist\n",
    "if not os.path.exists(\"faces\"):\n",
    "    os.makedirs(\"faces\")\n",
    "\n",
    "# Loop through all files in the directory and remove them\n",
    "for filename in os.listdir(\"faces\"):\n",
    "    file_path = os.path.join(\"faces\", filename)\n",
    "    try:\n",
    "        if os.path.isfile(file_path):\n",
    "            os.remove(file_path)\n",
    "    except Exception as e:\n",
    "        print(f\"Failed to delete {file_path}. Reason: {e}\")\n",
    "\n",
    "# Iterate over each face\n",
    "for i, face in enumerate(faces):\n",
    "    # Get the landmarks/parts for the face in box d.\n",
    "    landmarks = predictor(gray, face)\n",
    "\n",
    "    # Extract face region as a numpy array\n",
    "    x1, y1, x2, y2 = face.left(), face.top(), face.right(), face.bottom()\n",
    "    face_region = img[y1:y2, x1:x2]\n",
    "\n",
    "    # Convert face region to grayscale\n",
    "    face_gray = cv2.cvtColor(face_region, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Save the face region as a grayscale image in the \"faces\" directory\n",
    "    cv2.imwrite(f\"faces/{i}.png\", face_gray)\n",
    "\n",
    "# Destroy all windows\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d5188aa4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 30ms/step\n",
      "The person in the test image is: jareen\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "The person in the test image is: Devi\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "The person in the test image is: Khasim\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "The person in the test image is: guravaya\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "The person in the test image is: Jessika\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "The person in the test image is: Santhvana\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "The person in the test image is: Thrisali\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "The person in the test image is: VaraLakshmi\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "The person in the test image is: Harshitha\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "The person in the test image is: BhargaviS\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "The person in the test image is: Pawan\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "The person in the test image is: Sirisha\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "The person in the test image is: Sravani\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "The person in the test image is: Swathi\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "The person in the test image is: sripavan\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "The person in the test image is: Sowjanya\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "The person in the test image is: Sangeetha\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "The person in the test image is: sai\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "The person in the test image is: neeraja\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "The person in the test image is: Nagraju\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "The person in the test image is: Anand\n"
     ]
    }
   ],
   "source": [
    "# Set the directory path for the images\n",
    "dir_path = 'faces/'\n",
    "\n",
    "# Loop through all the files in the directory\n",
    "# for file_name in os.listdir(dir_path):\n",
    "#     # Check if the file is an image\n",
    "#     if file_name.endswith('.jpg') or file_name.endswith('.jpeg') or file_name.endswith('.png'):\n",
    "#         # Read the image and perform pre-processing\n",
    "#         test_img = cv2.imread(os.path.join(dir_path, file_name))\n",
    "#         test_img = cv2.resize(test_img, (img_size, img_size))\n",
    "#         test_img = np.array(test_img).reshape(-1, img_size, img_size, 3) / 255.0\n",
    "\n",
    "#         # Predict the person in the test image using the loaded model\n",
    "#         prediction = loaded_model.predict(test_img)\n",
    "#         person = names[np.argmax(prediction)]\n",
    "\n",
    "#         # Output the name of the person\n",
    "#         print(\"The person in the test image is:\", person)\n",
    "\n",
    "#         # Add the results to the DataFrame\n",
    "#         now = datetime.datetime.now().strftime('%Y-%m-%d %H:%M:%S')\n",
    "#         new_row = {'Image': file_name, 'Person': person, 'Date': now}\n",
    "#         results = pd.concat([results, pd.DataFrame(new_row, index=[0])])\n",
    "\n",
    "# # Write the results to an Excel file\n",
    "# results.to_excel('results.xlsx', index=False)\n",
    "\n",
    "\n",
    "for i in range(0,21):\n",
    "    test_img = cv2.imread('faces/'+str(i)+'.png')\n",
    "    test_img = cv2.resize(test_img, (img_size, img_size))\n",
    "    test_img = np.array(test_img).reshape(-1, img_size, img_size, 3) / 255.0\n",
    "\n",
    "    # Predict the person in the test image using the loaded model\n",
    "    prediction = loaded_model.predict(test_img)\n",
    "    person = names[np.argmax(prediction)]\n",
    "\n",
    "    # Output the name of the person\n",
    "    print(\"The person in the test image is:\", person)\n",
    "\n",
    "    # Add the results to the DataFrame\n",
    "    now = datetime.datetime.now().strftime('%Y-%m-%d %H:%M:%S')\n",
    "    new_row = {'Image': file_name, 'Person': person, 'Date': now}\n",
    "    results = pd.concat([results, pd.DataFrame(new_row, index=[0])])\n",
    "\n",
    "# Write the results to an Excel file\n",
    "results.to_excel('results.xlsx', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
